{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce5d8d8b-1b1f-4c3c-8bad-e0af5b66e8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from konlpy.tag import Okt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import requests\n",
    "import spacy\n",
    "import textacy.preprocessing as tprep\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c819d3-5d4f-4b76-9baf-595e5539e0af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "앞으로 할 것\n",
    "    1. 토큰화\n",
    "    2. 언어적 처리\n",
    "    3. 데이터 수집 성능 향상 -> 데이터 직접 요청하던가 할 것\n",
    "    4. 시각화, 요약보고\n",
    "\n",
    "토큰화 방법\n",
    "    - nltk, spacy, okt 활용\n",
    "    - 불용어 제거\n",
    "    - 조사 제거\n",
    "    - 너무 흔하면서 별 의미 없는 요소 제거해 특성 감소\n",
    "    - 너무 희소한 요소 제거해 특성 감소\n",
    "    - ngram 추가해 특성 확장\n",
    "    - 단어 정규화: 원형 복원\n",
    "    - 품사 태깅을 통한 특성 선별 (~ 조사 제거)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020f641-17e1-4e40-af8d-da3d297799ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_page(date):\n",
    "\n",
    "    BASE_URL = 'https://news.naver.com/main/list.naver?mode=LSD&mid=sec&listType=title&'\n",
    "\n",
    "    last_page = 1000\n",
    "\n",
    "    while True:\n",
    "        url = BASE_URL\n",
    "        url += f'date={date}&'\n",
    "        url += f'page={last_page}'\n",
    "\n",
    "        res = requests.get(url)\n",
    "        bs = BeautifulSoup(res.text)\n",
    "        time.sleep(1)\n",
    "\n",
    "        has_next = bs.find('a', class_='next nclicks(fls.page)')\n",
    "        page_list = bs.find('div', class_='paging')\n",
    "        \n",
    "        if not has_next and last_page >= int(page_list.find('strong').get_text()):\n",
    "            last_page = int(page_list.find('strong').get_text())\n",
    "            break\n",
    "        else :\n",
    "            last_page += 1000\n",
    "\n",
    "\n",
    "    return last_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8defe8-1fcc-4a92-9336-b85e78f30268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(start, end, time_sleep=0.5, page_start=1) :\n",
    "    BASE_URL = 'https://news.naver.com/main/list.naver?mode=LSD&mid=sec&listType=title&'\n",
    "\n",
    "    # page = 1\n",
    "    # date = datetime.datetime.now()\n",
    "    period = pd.date_range(date_start, date_end)\n",
    "    \n",
    "    for ts in period:\n",
    "        date = str(ts.year) + str(ts.month).zfill(2) + str(ts.day).zfill(2)\n",
    "        raw_data = {'titles': [], 'dates': []}\n",
    "        max_page = get_max_page(date)\n",
    "        print(f\"{date} ( MAX PAGE : {max_page} ) : \", end='')\n",
    "        page = page_start\n",
    "        pct = 0.1\n",
    "        \n",
    "        while True:\n",
    "            url = BASE_URL\n",
    "            url += f'date={date}&'\n",
    "            url += f'page={page}'\n",
    "    \n",
    "            res = requests.get(url)\n",
    "            bs = BeautifulSoup(res.text)\n",
    "            time.sleep(time_sleep)\n",
    "\n",
    "            raw_titles = [e.get_text() for e in bs.find_all('a', class_=\"nclicks(fls.list)\")]\n",
    "            raw_data['titles'].extend(raw_titles)\n",
    "            raw_data['dates'].extend([date]*len(raw_titles))\n",
    "\n",
    "            if page / max_page > pct :\n",
    "                print('*', end='')\n",
    "                pct += 0.1\n",
    "\n",
    "            has_next = bs.find('a', class_='next nclicks(fls.page)')\n",
    "            page_list = bs.find('div', class_='paging')\n",
    "            \n",
    "            if not has_next and page == int(page_list.find('strong').get_text()):\n",
    "                break\n",
    "            else : \n",
    "                page += 1\n",
    "\n",
    "        print(\"\\tDONE\", end=' / ')\n",
    "        save_raw_data(raw_data, date, 'tst_data')\n",
    "\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659d840-da52-4e32-9f4a-6dacec76b9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_raw_data(raw_data, fname, fpath):\n",
    "    with open(f'{fpath}/{fname}.pkl', 'wb') as f:\n",
    "        print('saving... ', end='')\n",
    "        pickle.dump(raw_data, f)\n",
    "        print('DONE')\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093aadb3-e136-4ee3-b7a9-a98cb75964ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(fname, fpath):\n",
    "    with open(f'{fpath}/{fname}.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26602d75-6ecf-4ae0-a497-744a7272ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "042724 : 20240101 ~ 20240425 크롤링\n",
    "\n",
    "'''\n",
    "\n",
    "date_start = '20240101'\n",
    "date_end = '20240425'\n",
    "\n",
    "raw_data = crawl(date_start, date_end, time_sleep=0.5, page_start=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a85fbdc-57d4-46ae-a510-0c1ed7927da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_raw_data('20240127', 'tst_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b16301-5643-40aa-b048-6582dc2ffb75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ab54ff-e21c-40fb-adfb-4019981754a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_raw_data('20240101_20240426')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d3f44-f67a-4c2f-858c-19a2e5543dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "crawl(20240404, 20240404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3f52c2-79f7-4346-9ca2-61a9bc0e15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('raw_data.pkl', 'rb') as f:\n",
    "        raw_data = pickle.load(f)\n",
    "\n",
    "except:\n",
    "    raw_data = crawl()\n",
    "\n",
    "np.random.choice(raw_data['titles'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3b112-f80f-4234-b22c-df6797196181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_punct_list(title):\n",
    "    return re.findall(r'[^ㄱ-ㅎ-가-힣\\w\\s\\(\\{\\[\\)\\}\\]]', title)\n",
    "\n",
    "def get_punct_set(titles):\n",
    "    punct_set = set()\n",
    "    titles.apply(lambda x: punct_set.update(get_punct_list(x)))\n",
    "    return punct_set\n",
    "\n",
    "def get_punct_freq(titles):\n",
    "    punct_set = get_punct_set(titles)\n",
    "    punct_freq = {p : 0 for p in punct_set}\n",
    "    for t in titles:\n",
    "        for p in get_punct_list(t):\n",
    "            punct_freq[p] += 1\n",
    "\n",
    "    return punct_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a21c11-9d03-4ac1-b1bd-1e1c1491e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.Series(raw_titles)\n",
    "punct_set = get_punct_set(titles)\n",
    "punct_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f6ee10-67a8-4502-9496-9f39cc81cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_freq = get_punct_freq(titles)\n",
    "punct_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda7746-cf05-4a96-ab7b-7877a41da718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "punct_info = pd.DataFrame([punct_freq.keys(), [ord(p) for p in punct_freq.keys()], punct_freq.values()]).T\n",
    "punct_info.sort_values(ascending=False, by=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56205465-8943-4cd9-8d80-88b23aa9ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impurity_score(title:str):\n",
    "    cpy = title[:]\n",
    "    cpy = re.sub(r'[\\(\\{\\[]+[ㄱ-ㅎ-가-힣\\w\\s,]+[^ㄱ-ㅎ-가-힣\\w\\s]*[\\]\\}\\)]+', '.', cpy)\n",
    "    cpy = re.sub(r'\\s', '', cpy)\n",
    "\n",
    "    n_chars = len(cpy) if len(cpy) != 0 else 1 # (copyright) 같은 제목 때문에 0 발생 -> 1로 처리\n",
    "    n_puncts = len(get_punct_list(cpy))\n",
    "    \n",
    "    return round(n_puncts / n_chars, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc2749-0b28-4fe6-bcf8-75284eb1480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_impurities = titles.apply(get_impurity_score).sort_values(ascending=False).head(10).index\n",
    "titles[top_10_impurities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034fc5d-569d-4711-8801-7a71c3423173",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSLATE_TABLE = { # 치환 후 없앨 것들 목록\n",
    "    ord(x) : ord(y) \n",
    "    for x, y\n",
    "    in [\n",
    "        ('［', '['),\n",
    "        ('％', '%'),\n",
    "        ('］', ']'),\n",
    "        ('″', '\"'),\n",
    "        ('”', '\"'),\n",
    "        ('‘', \"'\"),\n",
    "        ('∼', '~'),\n",
    "        ('`', \"'\"),\n",
    "        ('’', \"'\"),\n",
    "        ('“', '\"')\n",
    "    ]\n",
    "}\n",
    "\n",
    "TRANSLATE_TABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5d843f-0bea-41a6-bb8c-ff5e18ae38fe",
   "metadata": {},
   "source": [
    "('↓', 8595) ('&', 38) ('㎝', 13213) ('↑', 8593) ('→', 8594)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0633053d-db55-4ad7-83e7-bc0135e13efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_sokbo_into_ub(title):\n",
    "    return re.sub(r'[\\(\\{\\[]+[ㄱ-ㅎ-가-힣\\w\\s,]+[^ㄱ-ㅎ-가-힣\\w\\s]*[\\]\\}\\)]+', '_', title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210c592-adef-4007-a44b-593a67e38c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_punct(title):\n",
    "\n",
    "    punct_list = ['\\'', '\\\"', '…', ',', '‥', '!', '@', '#', '&', '/', '+', '=', '~', '?', '>', '_', '㈜', '↓', '↑', '→']\n",
    "    \n",
    "    title = rep_sokbo_into_ub(title) # (속보), [단독] 따위의 [000의 건강상식]과 같은 요소들은 .으로 변경\n",
    "    title = title.translate(TRANSLATE_TABLE)\n",
    "    \n",
    "    title = tprep.normalize.quotation_marks(title) # 따옴표 정규화\n",
    "    \n",
    "    title = re.sub(r'\\.\\.(\\.)?', '…', title) # 말줄임표 정규화 ('..' , '...' -> '…')\n",
    "    \n",
    "    title = tprep.normalize.bullet_points(title)\n",
    "    title = re.sub(r'·', ' ', title) # 불릿 표현 정규화 + 띄어쓰기로 변형 -> 추후 품사 태깅 등을 통해 낱말 조합 등 진행\n",
    "\n",
    "    # 필요 없는 문장부호 제거 \n",
    "    # + '‥' 추가 : 041324 1318\n",
    "    title = tprep.remove.punctuation(title, only=punct_list)\n",
    "    \n",
    "    title = re.sub('\\s+', ' ', title) # 위에서 생긴 연속 공백 제거\n",
    "    title = title.strip() # 양 끝 공백 제거\n",
    "    \n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd270e4d-d4bb-45b0-b08f-63d2f4b5762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_titles = titles.apply(normalize_punct)\n",
    "clean_titles.apply(get_impurity_score).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b6aa63-d6ba-418e-9d06-77e709dd1870",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "okt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd351fd-be68-4942-a3c5-9b44cc6fd3b1",
   "metadata": {},
   "source": [
    "요약보고\n",
    "\n",
    "20200101부터 20200108 까지의 기사를 분석한 결과입니다. 해당 기간 동안 (특정 n개 주제)가 새로 주목받기 시작했습니다. 반면 (특정 n개) 에 대한 관심은 줄어드는 추세를 보였습니다. (n개)는 꾸준한 관심을 보였습니다.\n",
    "\n",
    "- 새로 주목받기 시작한 키워드 : 시작일 경 top n 밖에 있다 새로 들어온 키워드\n",
    "- 관심 줄어드는 키워드 : 시작일 경 top n에 있다가 밖으로 나간 키워드\n",
    "- 꾸준한 관심 보이는 키워드 : 기간동안 단어 목록에서 top n 안에 계속 들어온 키워드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00b82e1-316b-4cfa-a5db-2a229303b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = clean_titles.apply(okt.morphs)\n",
    "tk = tk.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cadd84e-967d-4e23-a17b-f530bf9efe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d303e39b-3d62-41b0-a34e-92e467d548f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e359db-b1ac-4131-8ec4-031ad312aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_tfidf = TfidfVectorizer()\n",
    "ko_cntvec = CountVectorizer()\n",
    "\n",
    "ko_dt = ko_tfidf.fit_transform(tk)\n",
    "ko_ct = ko_cntvec.fit_transform(tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f71ebf-e942-4cee-92e0-9507499106f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wc_data_cnt(model, data, is_tfidf=False):\n",
    "    wc_data = np.c_[model.get_feature_names_out(), data.toarray().sum(axis=0)]\n",
    "    wc_data = wc_data[wc_data[ : , 1].argsort()]\n",
    "    wc_data = wc_data[-50 : ]\n",
    "    wc_data = {item[0]: item[1] for item in wc_data}\n",
    "\n",
    "    return wc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cedb572-0b6e-459b-beda-5c8595efaa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(font_path='C:/Windows/Fonts/malgun.ttf')\n",
    "cloud = wc.generate_from_frequencies(get_wc_data_cnt(ko_cntvec, ko_ct))\n",
    "\n",
    "# Display the word cloud using matplotlib\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('wc_ko_cntvec.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6e04f3-fdc1-4b58-aa6d-64d777d02fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_titles.sample(10).apply(okt.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003a350d-90f9-45f2-8152-f178530ce95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt.phrases(clean_titles[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e7e94f-a225-4d30-8522-ed2c801b90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt.tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19998d48-6366-44fb-a148-3db2c91db6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy import tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc660f8f-af75-4f20-a89c-3abec6ec16e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenize(title, kr_module):\n",
    "\n",
    "    josa_tag = None\n",
    "\n",
    "    if isinstance(komoran, tag.Okt): \n",
    "        josa_tag = ['Josa']\n",
    "    elif isinstance(komoran, tag.Komoran):\n",
    "        josa_tag = ['JKS', 'JKC', 'JKG', 'JKO', 'JKB', 'JKV', 'JKQ', 'JC', 'JX']\n",
    "    \n",
    "    title = kr_module.pos(title)\n",
    "    title = [t for t in title if t[1] not in josa_tag]\n",
    "    title = [t[0] for t in title]\n",
    "    title = ' '.join(title)\n",
    "\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a031ea87-36c0-4dee-baca-b13f07137df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "JKS\t주격 조사\n",
    "JKC\t보격 조사\n",
    "JKG\t관형격 조사\n",
    "JKO\t목적격 조사\n",
    "JKB\t부사격 조사\n",
    "JKV\t호격 조사\n",
    "JKQ\t인용격 조사\n",
    "JC\t접속 조사\n",
    "\t\n",
    "JX\t보조사\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f929b-656c-4893-9ec7-e09bf7720083",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tokenize(clean_titles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efdadc-47ff-47cd-a4dc-3e66320ae287",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tokenize(clean_titles[2403])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c789d18-46e2-45c3-a98e-051c747895d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctk = clean_titles.apply(custom_tokenize)\n",
    "\n",
    "custom_ct = ko_cntvec.fit_transform(ctk)\n",
    "\n",
    "wc = WordCloud(font_path='C:/Windows/Fonts/malgun.ttf')\n",
    "cloud = wc.generate_from_frequencies(get_wc_data_cnt(ko_cntvec, custom_ct))\n",
    "\n",
    "# Display the word cloud using matplotlib\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('wc_ko_cntvec.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06faabc6-c337-48a1-a80e-c222313f47ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tokenize('간담회 주재하는 김용삼 차관')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402e0bc1-f15d-4f32-827d-3febfa03a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt.pos('간담회 주재하는 김용삼 차관')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753a663-269d-4f19-83a0-4a9e0440d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('ko_core_news_sm')\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eba336c-b7fa-44d1-8b4a-4ce2af271e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.tokenize.word_tokenize('간담회 주재하는 김용삼 차관')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32658f-e12b-41b5-a1fb-5855de216a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy import tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc97b7-76f3-4188-8afe-a92aff6183ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "komoran = tag.Komoran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cee57a-c1e5-4980-abfd-6030ec0f1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_komoran = clean_titles.apply(custom_tokenize, kr_module=komoran)\n",
    "tk_komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907c377-47ee-49ab-9ede-6e052df1601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_kr = spacy.load('ko_core_news_sm')\n",
    "nlp_kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b6101-a10b-4167-93f4-db715e13f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_lemma(title, nlp):\n",
    "    doc = nlp(title)\n",
    "    return [(t, t.lemma_) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1be87f6-3702-4a77-877b-1f2ca3ea1443",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_spacy = clean_titles.apply(display_lemma, nlp=nlp_kr)\n",
    "tk_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef5e61-acda-43b5-81fa-733bc5b68605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168b48b1-bf5d-41e5-b3e6-bcb35b5153f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
